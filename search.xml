<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[搭建爬虫代理池]]></title>
      <url>http://yoursite.com/2016/08/02/%E6%90%AD%E5%BB%BA%E7%88%AC%E8%99%AB%E4%BB%A3%E7%90%86%E6%B1%A0/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>反爬虫的手段众多，最常见的是检查Header，其次是根据访问的频率封禁IP。网上可以找到许多提供代理的网站，但实际可用的IP甚少，购买收费接口也不是适合小型项目。因此，搭建一个自己的爬虫代理池是十分有必要的。<br><a id="more"></a></p>
<h3 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h3><p>程序运行示意图如下：<br><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160802/spider_result_pic.png" alt=""></p>
<p>数据库示意图如下：<br><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160802/spider_result_db.png" alt=""></p>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>要获取可用的代理IP，端口扫描效率太低，考虑到爬虫的日常需求量不大，从现有的代理网站爬下来最方便。实际测试过程中，发现网上的代理网站提供的IP可用率也很低，可能它们的检测规则是用百度等网站做靶子来查看返回值吧，然而这个办法并不准确，毕竟很多代理可能反代了百度等知名站点。</p>
<p>出于对X_FORWARDED_FOR处理方法的不同，网络上代理的分类分成了透明代理和匿名代理，其中匿名代理又分普匿代理和高匿代理。既然是为了爬虫的隐蔽性，那么只能考虑高匿代理，并且自己做验证。</p>
<h3 id="开发步骤"><a href="#开发步骤" class="headerlink" title="开发步骤"></a>开发步骤</h3><p>首先要找一些现有的代理网站，用Google可以搜出来一大堆。分析它们的特点，发现IP、port、protocol都是用表格显示的，自然而然想到用BeautifulSoup的find_all来筛选，再加上IP等数据的格式判定，就可以将所有网站的筛选规则统一，写成通用爬虫了。</p>
<p>爬下资料之后，要存入数据库，用了sqlite3，其实还是用了SQL的语法，所以最好再封装一下。</p>
<p>接下来就就是要验证IP的可用性了，这里采用 <a href="http://httpbin.org/ip" target="_blank" rel="external">http://httpbin.org/ip</a> 作为判断依据，如果返回的url与代理相同，则判定该IP可用。</p>
<p>判定IP可用之后，再调用淘宝的接口，得到IP的地理位置，更新到数据库中。</p>
<p>完整代码放在我的Github<a href="https://github.com/SymeonChen/spider-proxy-pool" target="_blank" rel="external">（https://github.com/SymeonChen/spider-proxy-pool）</a>上了。这里再贴一些关键的代码。</p>
<hr>
<p>判断IP是否可用，属于I/O密集型，所以采用多线程比较快，因此这里调用了multiprocessing.dummy。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> multiprocessing.dummy <span class="keyword">import</span> Pool <span class="keyword">as</span> ThreadPool</div><div class="line">pool = ThreadPool(<span class="number">30</span>)</div><div class="line"></div><div class="line">results = dboperation.selectAllAddress()</div><div class="line">pool.map(ipverify.checkAllAddress,results)</div><div class="line"></div><div class="line">pool.close()</div><div class="line">pool.join()</div></pre></td></tr></table></figure></p>
<hr>
<p>判断IP的格式是否正确，网上方法众多，这里调用ipaddress模块来完成检查，因此Python的版本必须大于3.3<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> ipaddress</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ip_isvalid</span><span class="params">(address)</span>:</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        ipaddress.IPv4Address(address)</div><div class="line">        <span class="keyword">return</span> <span class="keyword">True</span></div><div class="line">    <span class="keyword">except</span> ipaddress.AddressValueError:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">False</span></div></pre></td></tr></table></figure></p>
<hr>
<h3 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h3><ol>
<li>代理可用率低，如果需要超过100+代理，需要再增加爬取的网站。</li>
<li>未对外提供服务。可用IP虽有，如果做成API就更方便调用了。</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[神箭手爬虫试用体验]]></title>
      <url>http://yoursite.com/2016/07/24/%E7%A5%9E%E7%AE%AD%E6%89%8B%E7%88%AC%E8%99%AB%E8%AF%95%E7%94%A8%E4%BD%93%E9%AA%8C/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在几个站上看到神箭手爬虫的广告，进去试着用了一下，上手比较容易，功能的拓展没有Python写起来那么舒服。<br><a id="more"></a></p>
<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li>注册</li>
<li>在爬虫市场选择或自己开发一个爬虫</li>
<li>设置相关参数</li>
<li>测试后启动爬虫</li>
<li>导出数据</li>
</ol>
<p>神箭手的爬虫是用JavaScript来编写的，内容的解析用的是XPath、正则、JsonPath。集成了IP代理、JS加载等功能，官方的文档比较详细，爬虫运行的流程图如下：</p>
<p><img src="http://doc.shenjianshou.cn/image/imagecallbackFlowchart.jpg" alt=""></p>
<p>流程还是比较清晰的。爬虫的结构如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> configs = &#123;</div><div class="line">    domains: [<span class="string">"xxx"</span>],</div><div class="line">    scanUrls: [<span class="string">"xxxx"</span>],</div><div class="line">    contentUrlRegexes: [<span class="string">"xxx"</span>],</div><div class="line">    helperUrlRegexes: [<span class="string">"xxx"</span>],</div><div class="line">    fields: [</div><div class="line">        &#123;</div><div class="line">            name: <span class="string">"title"</span>,</div><div class="line">            selector: <span class="string">'xxx'</span>,</div><div class="line">            required: <span class="literal">true</span></div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            name: <span class="string">"content"</span>,</div><div class="line">            selector: <span class="string">'xxx'</span>,</div><div class="line">          	repeated: <span class="literal">true</span></div><div class="line">        &#125;,</div><div class="line">      	&#123;</div><div class="line">          	name: <span class="string">"article_author"</span>,</div><div class="line">          	selector: <span class="string">'xxx'</span></div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="keyword">var</span> crawler = <span class="keyword">new</span> Crawler(configs);</div><div class="line">crawler.start();</div></pre></td></tr></table></figure>
<p>在configs中定义了爬虫的参数，然后new一个Crawler对象来启动。</p>
<p>domains用于过滤不相关的网址，scanUrls是爬虫的入口页，contentUrlRegexes是内容页的正则过滤规则，helperUrlRegexes是列表页的正则过滤规则，fields中包含了内容页解析出来要保存的数据，selector默认是XPath规则，也可以指定成正则等，required表示该项不能为空，repeated表示该项不止一个。如果用XPath Helper来查看XPath过滤的元素的话，多个元素都会显示，但这里写的爬虫爬取的时候，只会爬满足条件的第一个，所以要指定repeated=true才行。</p>
<p>附一个今天早上写的Acfun文章区的爬虫：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> configs = &#123;</div><div class="line">    domains: [<span class="string">"www.acfun.tv"</span>],</div><div class="line">    scanUrls: [<span class="string">"http://www.acfun.tv/v/list110/index_1.htm"</span>],</div><div class="line">    contentUrlRegexes: [<span class="string">"http://www\\.acfun\\.tv/a/ac\\d&#123;7&#125;"</span>],</div><div class="line">    helperUrlRegexes: [<span class="string">"http://www\\.acfun\\.tv/v/list110/index_\\d+\\.htm"</span>],</div><div class="line">    enableJS: <span class="literal">true</span>,</div><div class="line">    fields: [</div><div class="line">        &#123;</div><div class="line">            name: <span class="string">"title"</span>,</div><div class="line">            selector: <span class="string">'//*[@id="title_1"]/span[2]'</span>,</div><div class="line">            required: <span class="literal">true</span></div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line"></div><div class="line">            name: <span class="string">"content"</span>,</div><div class="line">            selector: <span class="string">'//*[contains(@id,"area-player")]//p//text()'</span>,</div><div class="line">          	required: <span class="literal">true</span>,</div><div class="line">          	repeated: <span class="literal">true</span></div><div class="line">        &#125;,</div><div class="line">      	&#123;</div><div class="line">          	name: <span class="string">"article_author"</span>,</div><div class="line">          	selector: <span class="string">'//*[@id="block-info-bottom"]/div[2]/div/span[1]/a/nobr'</span>,</div><div class="line">          	required: <span class="literal">false</span></div><div class="line">        &#125;,</div><div class="line">      	&#123;</div><div class="line">      		name: <span class="string">"article_view_count"</span>,</div><div class="line">          selector: <span class="string">'//*[@id="txt-info-title_1"]/span[1]'</span>,</div><div class="line">        	required: <span class="literal">false</span></div><div class="line">      	&#125;,</div><div class="line">      	&#123;</div><div class="line">          name: <span class="string">"article_agree_count"</span>,</div><div class="line">          selector: <span class="string">'//*[@id="txt-info-title_1"]/span[5]'</span>,</div><div class="line">        	required: <span class="literal">false</span></div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="keyword">var</span> crawler = <span class="keyword">new</span> Crawler(configs);</div><div class="line">crawler.start();</div></pre></td></tr></table></figure>
<p>enableJS是因为阅读量与赞同量是js加载的。content部分用了//p//text()，因为一部分页面多套了一层div，一部分页面的内容夹杂在span与p里。</p>
<p>更多用法可以看官方的文档。</p>
<h3 id="体验"><a href="#体验" class="headerlink" title="体验"></a>体验</h3><p>爬虫还是用Python来写更舒服。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[通过CloudFlare开启全站https]]></title>
      <url>http://yoursite.com/2016/07/17/%E9%80%9A%E8%BF%87CloudFlare%E5%BC%80%E5%90%AF%E5%85%A8%E7%AB%99https/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本站托管于<a href="https://pages.github.com/" target="_blank" rel="external">Github Pages</a>，使用<a href="https://hexo.io/zh-cn/" target="_blank" rel="external">Hexo</a>搭建而成，原本域名为symeonchen.github.io，有Github的SSL证书，但指向自定义域名后则使得证书的网址对应不上，变为HTTP访问。毕竟HTTPS是大势所趋，经过一番折腾，最终使用了CloudFlare作为代理，成功给全站开启了HTTPS。<br><a id="more"></a></p>
<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li>购买域名</li>
<li>注册登陆<a href="https://www.cloudflare.com/" target="_blank" rel="external">CloudFlare</a>，一步步设置，将域名服务商提供的DNS服务指向CloudFlare</li>
<li>进行配置，推荐在Page Rules中开启Always Use HTTPS，在Crypto中开启HSTS</li>
</ol>
<p>域名symeonchen.com是在<a href="https://sg.godaddy.com/zh/" target="_blank" rel="external">GoDaddy</a>买的，GoDaddy的DNS服务太慢，故原本托管于<a href="https://www.dnspod.cn/" target="_blank" rel="external">DNSPod</a>。现在用了CloudFlare的服务，所以又将DNS从DNSPod挪到了CloudFlare。免费的plan已经够用，速度上也还不错，虽然在Github与CloudFlare之间的传输仍有不安全的因素，但CloudFlare与访问者之间已经成功使用了HTTPS。</p>
<p>域名提供商处，改为指向</p>
<blockquote>
<p>hera.ns.cloudflare.com</p>
</blockquote>
<p>与</p>
<blockquote>
<p>jeff.ns.cloudflare.com</p>
</blockquote>
<p>这两处</p>
<p>然后在CloudFlare中设置DNS的CNAME，将www指向symeonchen.github.io。如果之前有在其他域名提供商处设置过Github Pages的自定义域名，那么CloudFlare会自动设置好CNAME与根目录的配置，十分人性化.</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[爬虫模拟登陆某校教务处]]></title>
      <url>http://yoursite.com/2016/07/16/%E7%88%AC%E8%99%AB%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86%E6%9F%90%E6%A0%A1%E6%95%99%E5%8A%A1%E5%A4%84/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>自从教务处改版后，本想用微信公众号“西二在线”查成绩，结果发现其功能一直处在几乎不能用的状态，恰逢假期，学校服务器负担小，自己尝试用Python写了个爬虫模拟登陆学校教务处，爬下成绩等信息。<br><a id="more"></a></p>
<h3 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h3><p><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160716/fzu_jwc_screenshot.png" alt=""><br>这是登陆成功的默认加载页面，在会话过期之前，可以从这个页面继续通过id访问其他所有信息，如成绩、课表、绩点等。</p>
<h3 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h3><p>既然登陆成功了，想要获取什么信息都可以了。无非是Get的Url稍有不同。</p>
<p><em>当然也可以用来爆破，不过效率低，也容易被发现。本文不进行此方面的研究讨论。</em></p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>模拟登陆，就是通过Python构造出与网页登陆相同的Request，再通过分析Response来获取我们想要的信息。</p>
<p>Python用来写爬虫有着得天独厚的优势，特别是<a href="http://docs.python-requests.org/en/master/" target="_blank" rel="external">Requests</a>库，大大节约了我们的时间。在此附上Requests的一句话简介：</p>
<blockquote>
<p>Requests: HTTP for Humans</p>
</blockquote>
<p>如果有用Urllib、Urllib2写过爬虫，那么体会一定很深刻。</p>
<h3 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h3><p>实验环境:</p>
<ul>
<li>抓包分析工具： Fiddler 或 Charles</li>
<li>Python版本： Python3.X</li>
</ul>
<p>首先，我们要分析登陆的过程。</p>
<p>使用Chrome打开<a href="http://jwch.fzu.edu.cn/" target="_blank" rel="external">某校教务处网站</a>，查看其源代码，找到输入账号密码的部分<br><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">name</span>=<span class="string">"loginform"</span> <span class="attr">id</span>=<span class="string">"loginform"</span> <span class="attr">method</span>=<span class="string">"post"</span> <span class="attr">action</span>=<span class="string">"http://59.77.226.32/logincheck.asp"</span> <span class="attr">onsubmit</span>=<span class="string">"return ew_ValidateForm(this);"</span> <span class="attr">_lpchecked</span>=<span class="string">"1"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">table</span> <span class="attr">align</span>=<span class="string">"center"</span> <span class="attr">width</span>=<span class="string">"100%"</span>&gt;</span><span class="tag">&lt;<span class="name">tbody</span>&gt;</span><span class="tag">&lt;<span class="name">tr</span>&gt;</span><span class="tag">&lt;<span class="name">td</span>&gt;</span></div><div class="line">    用户名：<span class="tag">&lt;<span class="name">input</span> <span class="attr">class</span>=<span class="string">"minput"</span> <span class="attr">size</span>=<span class="string">"10"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">id</span>=<span class="string">"muser"</span> <span class="attr">name</span>=<span class="string">"muser"</span> <span class="attr">style</span>=<span class="string">"cursor: auto; background-image: url(&amp;quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR4nGP6zwAAAgcBApocMXEAAAAASUVORK5CYII=&amp;quot;);"</span> <span class="attr">autocomplete</span>=<span class="string">"off"</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></div><div class="line">    密　码：<span class="tag">&lt;<span class="name">input</span> <span class="attr">class</span>=<span class="string">"minput"</span> <span class="attr">size</span>=<span class="string">"10"</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">id</span>=<span class="string">"passwd"</span> <span class="attr">name</span>=<span class="string">"passwd"</span> <span class="attr">value</span>=<span class="string">""</span> <span class="attr">style</span>=<span class="string">"cursor: auto; background-image: url(&amp;quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR4nGP6zwAAAgcBApocMXEAAAAASUVORK5CYII=&amp;quot;);"</span> <span class="attr">autocomplete</span>=<span class="string">"off"</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">td</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">td</span> <span class="attr">align</span>=<span class="string">"right"</span>&gt;</span></div><div class="line">         <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"button"</span>&gt;</span></div><div class="line">           <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"image"</span> <span class="attr">src</span>=<span class="string">"/template/style/login/button1.gif"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span>   </div><div class="line">    <span class="tag">&lt;/<span class="name">td</span>&gt;</span>    </div><div class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">tbody</span>&gt;</span><span class="tag">&lt;/<span class="name">table</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>从源代码中我们可以看到，当点击“登陆”按钮时，会向<a href="http://59.77.226.32/logincheck.asp" target="_blank" rel="external">http://59.77.226.32/logincheck.asp</a> post一些数据。</p>
<p>现在，我们再打开Charles或者Fiddler进行抓包，抓包工具的使用及设置不在此赘述。以Charles为例，在Chrome中设置代理之后访问并登陆某校教务处，可以抓到如下图所示的数据包</p>
<p><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160716/fzu_jwc_charles_capture.png" alt=""></p>
<p>我们查看logincheck.asp的Request如下</p>
<p><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160716/fzu_jwc_login_request.png" alt=""></p>
<p>muser部分的值为学号，passwd的值为密码，不太客气地说，明文传输实在不安全。但奇怪的是，从刚才的表单中我们可以看到，只填写了muser和passwd的值，但post的数据却包含了x和y，如果多次抓包还会发现这两个值是变化的。经实验发现，x和y的值不影响登陆过程，从<a href="http://stackoverflow.com/questions/801702/how-to-remove-x-and-y-on-submit-in-html-form-with-image-type-button" target="_blank" rel="external">stackoverflow</a>上查到，原来x和y值是鼠标点击button时的相对坐标，因为button的type是image，所以在submit的时候会带上这两个参数。</p>
<p>Response如下</p>
<p><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160716/fzu_jwc_login_response.png" alt=""></p>
<p>我们可以看到，回传的状态码为302，而不是正常的200。</p>
<p>到目前位置，用代码先实现如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line">header_info = &#123;</div><div class="line">    <span class="string">'Cache-Control'</span>:<span class="string">'max-age=0'</span>,</div><div class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'</span>,</div><div class="line">    <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'</span>,</div><div class="line">    <span class="string">'Origin'</span>: <span class="string">'http://jwch.fzu.edu.cn'</span>,</div><div class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate'</span>,</div><div class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8,en;q=0.6'</span>,</div><div class="line">    <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</div><div class="line">    <span class="string">'Upgrade-Insecure-Requests'</span>: <span class="string">'1'</span>,</div><div class="line">    <span class="string">'Referer'</span>: <span class="string">'http://jwch.fzu.edu.cn/'</span>,</div><div class="line">    <span class="string">'Content-Type'</span>: <span class="string">'application/x-www-form-urlencoded'</span>,</div><div class="line">    &#125;</div><div class="line">login_form=&#123;</div><div class="line">    <span class="string">'muser'</span> : <span class="string">'学号'</span>,</div><div class="line">    <span class="string">'passwd'</span>: <span class="string">'密码'</span>,</div><div class="line">    <span class="string">'x'</span>     : <span class="string">'39'</span>,</div><div class="line">    <span class="string">'y'</span>     : <span class="string">'22'</span></div><div class="line">&#125;</div><div class="line">r = requests.post(<span class="string">'http://59.77.226.32/logincheck.asp'</span>,data = login_form,headers = header_info)</div><div class="line">print(r.text)</div></pre></td></tr></table></figure>
<p>运行之后会发现，回传的页面是错误页面，抓包后会发现Response部分是正常的。这是怎么回事呢？上面提到，回传的状态码为302，而Python的Requests库会自动重定向，自然就重定向到了错误的页面。所以我们要将代码的post部分进行修改，添加一个参数allow_redirects。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">r = requests.post(<span class="string">'http://59.77.226.32/logincheck.asp'</span>,data = login_form,headers = header_info, allow_redirects = <span class="keyword">False</span>)</div></pre></td></tr></table></figure></p>
<p>这样，就不会自动重定向了。</p>
<p>现在，我们将从Response中解析出网址，从图中可以看到，所有获取的内容结构清晰，因此采用beautifulsoup来解析。需先安装BeautifulSoup4<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo pip3 install beautifulsoup4</div></pre></td></tr></table></figure></p>
<p>然后用其来解析结构<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line">soup = BeautifulSoup(r.text,<span class="string">"lxml"</span>)</div><div class="line">new_url = soup.body.a.get(<span class="string">"href"</span>)</div><div class="line">print(new_url)</div></pre></td></tr></table></figure></p>
<p>就可以获得新的网址。</p>
<p>同理，分析抓包获得的第二个数据包，<br><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160716/fzu_jwc_loginchk_request.png" alt=""><br>可以看到使用了get来获取信息，其Response一样是302状态码<br><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160716/fzu_jwc_loginchk_response.png" alt=""><br>因此，同理<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">new_r = requests.get(new_url,headers=header_info,allow_redirects=<span class="keyword">False</span>)</div><div class="line">new_soup = BeautifulSoup(new_r.text,<span class="string">"lxml"</span>)</div><div class="line">re_url = new_soup.body.a.get(<span class="string">"href"</span>)</div><div class="line">print(re_url)</div></pre></td></tr></table></figure></p>
<p>Response中的default页面，就是成功登陆后的页面元素了。<br><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160716/fzu_jwc_default_request.png" alt=""><br><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160716/fzu_jwc_default_response.png" alt=""></p>
<p>完整代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python</span></div><div class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"></div><div class="line">header_info = &#123;</div><div class="line">    <span class="string">'Cache-Control'</span>:<span class="string">'max-age=0'</span>,</div><div class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'</span>,</div><div class="line">    <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'</span>,</div><div class="line">    <span class="string">'Origin'</span>: <span class="string">'http://jwch.fzu.edu.cn'</span>,</div><div class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate'</span>,</div><div class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8,en;q=0.6'</span>,</div><div class="line">    <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</div><div class="line">    <span class="string">'Upgrade-Insecure-Requests'</span>: <span class="string">'1'</span>,</div><div class="line">    <span class="string">'Referer'</span>: <span class="string">'http://jwch.fzu.edu.cn/'</span>,</div><div class="line">    <span class="string">'Content-Type'</span>: <span class="string">'application/x-www-form-urlencoded'</span>,</div><div class="line">    &#125;</div><div class="line"></div><div class="line">login_form=&#123;</div><div class="line">    <span class="string">'muser'</span> : <span class="string">'学号'</span>,</div><div class="line">    <span class="string">'passwd'</span>: <span class="string">'密码'</span>,</div><div class="line">    <span class="string">'x'</span>     : <span class="string">'42'</span>,</div><div class="line">    <span class="string">'y'</span>     : <span class="string">'12'</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">r = requests.post(<span class="string">'http://59.77.226.32/logincheck.asp'</span>,data = login_form,headers = header_info, allow_redirects = <span class="keyword">False</span>)</div><div class="line">soup = BeautifulSoup(r.text,<span class="string">"lxml"</span>)</div><div class="line">new_url = soup.body.a.get(<span class="string">"href"</span>)</div><div class="line"><span class="comment">#print(new_url)</span></div><div class="line">new_r = requests.get(new_url,headers=header_info,allow_redirects=<span class="keyword">False</span>)</div><div class="line">new_soup = BeautifulSoup(new_r.text,<span class="string">"lxml"</span>)</div><div class="line">re_url = new_soup.body.a.get(<span class="string">"href"</span>)</div><div class="line"><span class="comment">#print(re_url)</span></div><div class="line">re_r = requests.get(re_url,headers=header_info)</div><div class="line">print(re_r.text)</div></pre></td></tr></table></figure></p>
<h3 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h3><p>如果输错密码，则发送get请求至loginchk.aspx的时候，即文中第二次回传302状态码时，不会回传302，而是200，可以此作为判断密码正误的条件。</p>
<p>登陆之后如果请求成绩等页面，会发现回传的多是表格，用BeautifulSoup来解析就不太容易了。可以考虑与正则、lxml等混合使用。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[获取鼠标坐标的小工具开发]]></title>
      <url>http://yoursite.com/2016/07/14/%E8%8E%B7%E5%8F%96%E9%BC%A0%E6%A0%87%E5%9D%90%E6%A0%87%E7%9A%84%E5%B0%8F%E5%B7%A5%E5%85%B7%E5%BC%80%E5%8F%91/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>打算做一个自动化的工具，发现获取鼠标当前坐标的值有点麻烦，截图然后用Photoshop的标尺来查看太浪费时间了，于是写了个小工具用来获取坐标。用的是autopy这个库来实现功能，Tkinter来绘制界面。方便下一步进行其他的开发。<br><a id="more"></a></p>
<h3 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h3><p>当我们按下<strong>Enter</strong>或点击Print按钮的时候，如果上方输入框均为非空，就会将框内坐标打印到底下的文本框中，否则会打印当前鼠标顶点所在坐标。</p>
<p><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160714/get_point_tool.png" alt=""></p>
<h3 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h3><p>可以快速记录下要使用的坐标为多少，方便之后进行自动化的处理。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>autopy是一个轻量级的跨平台Python库，主要有模拟按键及鼠标、处理颜色及图像等功能。其图像部分并不如PIL那么广为人知，自动化方面也不如pywin32那么出名。但其用法简单且不受平台限制，用来模拟点击十分好用。</p>
<p>Tkinter是Python自带的GUI库，布局粗糙，界面朴素，但其跨平台稳定，所以用在这种小工具上再合适不过了。相比之下，PyQt虽然界面丰富，在这种场景下就则略显臃肿了。</p>
<h3 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h3><p>实验环境：</p>
<ul>
<li>Python 2.X</li>
</ul>
<p>首先安装autopy，在autopy的安装过程中可能会报如下错误:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">error: command &apos;x86_64-linux-gnu-gcc&apos; failed with exit status 1</div></pre></td></tr></table></figure></p>
<p>解决办法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install libx11-dev libxtst-dev libpng-dev</div></pre></td></tr></table></figure></p>
<p>然后再安装即可。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo pip install autopy</div></pre></td></tr></table></figure></p>
<p>安装完成之后，测试一下能否获取到坐标<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> autopy</div><div class="line"><span class="keyword">print</span> autopy.mouse.get_pos()</div></pre></td></tr></table></figure></p>
<p>现在开始编写GUI，并不复杂，直接贴代码了<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> autopy</div><div class="line"><span class="keyword">from</span> Tkinter <span class="keyword">import</span> *</div><div class="line"></div><div class="line">master = Tk()</div><div class="line">master.title(<span class="string">"Get Point Tool"</span>)</div><div class="line"></div><div class="line"><span class="comment">#columnspan=2表示横跨两个column</span></div><div class="line">Label(master,text = <span class="string">"Press Enter to get New Point"</span>).grid(row = <span class="number">0</span>, columnspan = <span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="comment">#sticky=E表示向右对齐</span></div><div class="line">Label(master, text = <span class="string">'x = '</span>).grid(row = <span class="number">1</span>, sticky = E)</div><div class="line">Label(master, text = <span class="string">'y = '</span>).grid(row = <span class="number">2</span>, sticky = E)</div><div class="line"></div><div class="line">e1 = Entry(master)</div><div class="line">e2 = Entry(master)</div><div class="line">e1.grid(row = <span class="number">1</span>, column = <span class="number">1</span>, sticky = W)</div><div class="line">e2.grid(row = <span class="number">2</span>, column = <span class="number">1</span>, sticky = W)</div><div class="line"></div><div class="line"><span class="comment">#将坐标插入文本框</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_point</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">if</span>(e1.get()==<span class="string">""</span> <span class="keyword">or</span> e2.get()==<span class="string">""</span>):</div><div class="line">        text_output.insert(<span class="number">0.0</span>, str(autopy.mouse.get_pos())+<span class="string">"\n"</span>)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        text_output.insert(<span class="number">0.0</span>, <span class="string">"("</span>+e1.get()+<span class="string">","</span>+e2.get()+<span class="string">")"</span> + <span class="string">"\n"</span>)</div><div class="line">        <span class="comment">#清空x、y两个文本框的值，delete(0,1000)表示删除第0位到第1000位的值</span></div><div class="line">        e1.delete(<span class="number">0</span>,<span class="number">1000</span>)</div><div class="line">        e2.delete(<span class="number">0</span>,<span class="number">1000</span>)</div><div class="line"></div><div class="line"></div><div class="line">Button(master, text = <span class="string">"Print"</span>, command = print_point).grid(row = <span class="number">3</span>, columnspan = <span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="comment">#将Return键与函数绑定，注意这里要用lambada</span></div><div class="line">master.bind(<span class="string">'&lt;Return&gt;'</span>,<span class="keyword">lambda</span> event:print_point())</div><div class="line"></div><div class="line">text_output = Text(master)</div><div class="line">text_output.grid(row = <span class="number">4</span>,columnspan = <span class="number">2</span>)</div><div class="line">text_output.config(width=<span class="number">30</span>)</div><div class="line"></div><div class="line"></div><div class="line">mainloop()  <span class="comment">#消息循环</span></div></pre></td></tr></table></figure></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[使用Python将文件隐藏于图片中]]></title>
      <url>http://yoursite.com/2016/07/11/%E4%BD%BF%E7%94%A8Python%E5%B0%86%E6%96%87%E4%BB%B6%E9%9A%90%E8%97%8F%E4%BA%8E%E5%9B%BE%E7%89%87%E4%B8%AD/</url>
      <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>网上有很多用指令将文件隐藏在图片中的方法，这也可以用Python来实现,它避开了对链接或文本进行匹配的屏蔽方法。网上流传的多是rar格式，闲来试了试，zip也可以，查找了一些资料，将过程整理如下。<br><a id="more"></a></p>
<h3 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h3><p>将这张图右键保存，可以看到是一张后缀为JPG的图片</p>
<p><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160711/before.jpg" alt=""></p>
<p>但重命名为以zip为后缀的压缩包后，会得到其他的文件</p>
<p><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160711/screenshot_after_zip.png" alt=""></p>
<h3 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h3><ul>
<li><strong>轻度</strong>提高文件的安全性</li>
<li>规避大多数<strong>字符串</strong>屏蔽规则</li>
</ul>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>JPG图片是二进制，其以0xFF,0xD8作为文件的SOI(Start Of Image)，以0xFF,0XD9作为文件的EOI(End Of Image)。详细结构见<a href="https://en.wikipedia.org/wiki/JPEG#Syntax_and_structure" target="_blank" rel="external">wiki</a></p>
<p>以图片begin.JPG为例，我们可以用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexdump -C before.JPG | head</div></pre></td></tr></table></figure></p>
<p>以及<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexdump -C before.JPG | tail</div></pre></td></tr></table></figure></p>
<p>来查看其二进制值<br><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160711/before_binary_head_and_%20tail.png" alt=""></p>
<p>同理，我们查看zip文件的二进制值，其Local file header Signature与End of central directory record Signature分别为0x504b0304和0x504b0506，详细结构见<a href="https://users.cs.jmu.edu/buchhofp/forensics/formats/pkzip.html" target="_blank" rel="external">这里</a></p>
<p><img src="http://oa5cno1tg.bkt.clouddn.com//web/image/20160711/zip_binary_head_and_%20tail.png" alt=""></p>
<p>我们将两个二进制文件拼接成一个，因JPG格式必须以特殊标识作为文件头，zip与rar等只需要包含特殊标识即可，因此生成的文件冠以不同后缀时，可作为不同文件格式使用。这种文件又称之为Poyglot,引用<a href="https://en.wikipedia.org/wiki/Polyglot_(computing)" target="_blank" rel="external">wiki</a>上的定义：</p>
<blockquote>
<p>In computing, a polyglot is a computer program or script written in a valid form of multiple programming languages, which performs the same operations or output independent of the programming language used to compile or interpret it.</p>
</blockquote>
<h3 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h3><p>实验环境：</p>
<ul>
<li>Linux操作系统</li>
<li>Python 2.x</li>
<li>一张标准JPG图片（文中为before.JPG）</li>
<li>一个txt文件（文中为test.txt）</li>
</ul>
<p>要实现这个功能，方法多种多样，甚至一行代码如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat test.zip &gt;&gt; before.JPG</div></pre></td></tr></table></figure></p>
<p>都可以实现。但现在我们可以使用Python，进行更多的探索。</p>
<p>步骤：</p>
<ol>
<li>将txt文件转换为zip文件</li>
<li>读取zip文件与JPG文件</li>
<li>拼接读取到的二进制值，写入新生成的JPG文件</li>
</ol>
<p>首先，生成zip文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> zipfile</div><div class="line"><span class="keyword">with</span> zipfile.ZipFile(<span class="string">'test.zip'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f_zip:</div><div class="line">    f_zip.write(<span class="string">'test.txt'</span>)</div></pre></td></tr></table></figure></p>
<p>然后读取zip文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> open(<span class="string">'test.zip'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</div><div class="line">    data_txt = f.read()</div></pre></td></tr></table></figure></p>
<p>同理，读取JPG文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> open(<span class="string">'before.JPG'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</div><div class="line">    data_JPG = f.read()</div></pre></td></tr></table></figure></p>
<p>最后，写入新的JPG<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> open(<span class="string">'after.JPG'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">    data = data_JPG + data_txt</div><div class="line">    f.write(data)</div></pre></td></tr></table></figure></p>
<p>最后，删除生成的zip文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os</div><div class="line">os.remove(<span class="string">'test.zip'</span>)</div></pre></td></tr></table></figure></p>
<p>这样，便将txt文件成功藏入JPG文件之中了。</p>
<h3 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h3><p>在生成zip文件时候，可以写入多个文件。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> zipfile</div><div class="line"><span class="keyword">with</span> zipfile.ZipFile(<span class="string">'test.zip'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f_zip:</div><div class="line">    f_zip.write(<span class="string">'test.txt'</span>)</div><div class="line">    f_zip.write(<span class="string">'test1.txt'</span>)</div></pre></td></tr></table></figure></p>
<p>zipfile也支持在打包成zip的同时进行压缩<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> zipfile.ZipFile(<span class="string">'test.zip'</span>, <span class="string">'w'</span>,zipfile.ZIP_DEFLATED) <span class="keyword">as</span> f_zip:</div><div class="line">    f_zip.write(<span class="string">'test.txt'</span>)</div></pre></td></tr></table></figure></p>
<p>如果需要压缩一整个文件夹，可以用glob遍历文件夹里的文件名,生成列表<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> glob</div><div class="line">files = glob.glob(filepath)</div></pre></td></tr></table></figure></p>
<p>之所以选择zip，是因为Python对zip原生支持，如果要用rar也可以，可以选择rarfile或者其他第三方模块即可。</p>
]]></content>
    </entry>
    
  
  
</search>
